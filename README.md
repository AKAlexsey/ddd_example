# CtiKaltura

Реализует редирект клиента на ближайший Edge сервер в CDN сети.

# Amnesia
В качестве базы данных в CtiKaltura используется Amnesia враппер на Elixir вокруг Mnesia.
Позволяет пользоваться Mnesia гораздо удобнее. Например при запросе возвращает структуру с именованными полями
а не кортеж, где надо разбираться какое значение является каким полем. 
Таблицы описаны в файле `/lib/cti_kaltura/caching/domain_model.ex`
Перед использованием необходимо инициировать базу данных.

```elixir
mix amnesia.create -d DomainModel --memory
```

Схема будет создана, параметр `--memory` указывает на то, что данные будут храниться в памяти.

## Возможные проблемы

### Изменение атрибутов одной из таблиц

Если изменились поля одной из таблиц DomainModel, то операции чтения и записи будут возвращать :badarg.

Причина:     
Схема сохранена на диск и она содержит старую структуру таблиц.      

Решение:      
Локально или после деплоя - дропнуть и создать заново схему базу данных.     

```elixir
mix amnesia.drop -d DomainModel
mix amnesia.create -d DomainModel --memory
mix amnesia.create_indexes
```

### Что делать в продакшн режиме или на стейдже при изменении атрибутов одной из таблиц

Была добавлена команда: `make_mnesia_cluster_again`    
Нужно зайти по ssh на сервер и выполнить `~/cti_kaltura/bin/cti_kaltura make_mnesia_cluster_again`
Исходя из названия, скрипт делает Mnesia кластерной, но скрипт так же может работать и на единичном ядре.
Если приложение должно работать в кластере, то оба ядра должны быть запущены.    

# Нагрузочное тестирование

Как фреймворк для нагрузочного тестирования используется "k6" https://github.com/loadimpact/k6

Документация доступна по ссылке https://docs.k6.io/docs

Скачайте и установите фреймворк по указаниям на Github.
Сделайте файл k6 исполняемым, чтобы можно было запускать тесты с помошью `k6 --option1 --option2 load_testing/test.js` 

Файлы нагрузочного тестирования находятся в `load_testing/*`

Для проведения проверки live запросов, необходимо запустить:
`k6 run --vus 300 --rps 200 --duration 300s load_testing/test_live.js`, где:

* `--vus` - количесво виртуальных пользователей;
* `--rps` - количесво запросов в секунду;
* `--duration` - продолжительность тестирования. Доступные форматы: 40s, 20m40s.

Для тестирования всех запросов:      
`k6 run --vus 300 --rps 200 --duration 300s load_testing/test_requests.js`     

Также доступна возможность строить более сложные сценарии скриптов - разное количество людей, разное количество 
запросов, разная продолжительность тестирования. Для этого используйте опции https://docs.k6.io/docs/options 
Необходимо пометить соответствующие настройки в переменную `options` и запустить тест без параметров. 

# Деплой

Деплой осуществляется при помощи скрипта `deploy.sh`, располагающегося в корне проекта.
Прежде чем задеплоить на стейдж убедитесь что у вас добавлен пароль для удалённого доступа по ssh на:
1. `admintv@10.15.2.20` - для production core1;
2. `admintv@172.16.2.143` - для stage core1.
2. `admintv@172.16.2.6` - для stage core2.

Команды деплоя:
1. Чтобы задеплоить на production core1 - `./deploy.sh prod1`;
2. Чтобы задеплоить на production core2 - `./deploy.sh prod2` (Пока второго сервера нет);
3. Чтобы задеплоить на stage core1 - `./deploy.sh stage1`;
4. Чтобы задеплоить на stage core2 - `./deploy.sh stage2`.

## Изменения в assets

Если были внесены изменения в ассеты (Добавлены, изменены css или js файлы), необходимо сгенерировать новый дайджест: `mix phx.digest`.
После этого будут внесены изменения в priv/static - необходимо закоммитить изменния и запушить.
После деплоя - изменения будут доступны на сервере.

## Миграции

После деплоя автоматически прогоняются миграции с помощью команды `migrate`
Если необходимо выполнить их в ручную - запустите `~/cti_kaltura/bin/cti_kaltura migrate`

## Подготовка к деплою

Прежде чем задеплоить проект, необходимо выполнить подготовительные работы на сервере. Необходимо:

1. Создать на стейдж сервере пользователя `admintv` для production или `app` для stage.      
Далее действия будут описываться за пользователя `admintv`;    
2. Установить git;
3. Для пользователя `admintv` установить на стейдж сервер соответствующие версии Elixir и Elrang. 
Указанные в файле `.tool-versions`. На момент написания документации: Elixir - 1.6.3, Erlang - 20.2.2.

4. Установить или использовать имеющуюся Postgres. Добавить необходимую базу данных, которая будет 
использоваться в проекте. Необходимо добавить разрешение на авторизацию в pg_hba.conf:   

```
local   all         postgres                          ident
```

Ссылка на объяснение проблемы:    
`https://stackoverflow.com/questions/7695962/postgresql-password-authentication-failed-for-user-postgres`    

5. За пользователя `admintv` создать папку `/home/admintv/cti_kaltura_build/`.
Создать папку `/home/admintv/cti_kaltura_build/build` внутри.

6. Прописать настройки БД и IP в конфигурации для соответствующего окружения для CtiKaltura.Repo, CtiKaltura.Endpoint.
В файл `/home/admintv/cti_kaltura_build/prod.secret.exs` при компиляции он автоматически подхватывается и испоьзуются при
компиляции настроек проекта.

7. Загрузить и настроить NGINX. Ниже описанны настройки и причина почему они должны быть добавлелны:

7.1 Основная причина - только системные утилиты могут быть запущены на порте меньшем 1000.
Следовательно проект должен быть запущен под root пользователем, что плохо.
Вместо этого мы запускаем за пользователя admintv на 4000 и 4001 портах.
* Запросы к 4000 порту не проксируем, если будет необходимо - пользователи зайдут сами по 4000 порту.

Добавить в конфигурацию NGINX секцию:

```
server {
  listen 80;
  server_name _;
}
```

7.2 При проксирвоании через NGINX IP адрес запроса - становится IP адресом NGINX.
Следовательно мы не можем определить IP адрес с которого пришёл запрос.
IP клиента было решено передавать в качетсве `http` заголовка.
Добавить в секцию `server`:

```   
proxy_set_header  Host            $host;
proxy_set_header  X-Real-IP       $remote_addr;
proxy_set_header  X-Forwarded-For $proxy_add_x_forwarded_for;
```

Соответственно проект будет читать IP адрес из `X-Real-IP` заголовка, если его нет - из `remote_ip` из %Plug.Conn{}.
При извлечении даных для запроса в `DataReader`.

7.3. Проксирование запросов с 80 порта на 4001 (запросы клиентов). Добавить в секцию `server`:

```
location /btv/live/ {
		proxy_pass http://<project_ip>:4001;
		add_header Access-Control-Allow-Origin *;
		break;
}
    
location /btv/catchup/ {
		proxy_pass http://<project_ip>:4001;
		break;
}
    
location /vod/ {
		proxy_pass http://<project_ip>:4001;
		break;
}
```

7.4. Обрезка расширений при запросах от приставок на `catchup` и `live`.
Приставки отправляют расширение для контента при `catchup` и `live` запросах.
Вида `http://cdn.beetv.kz/btv/live/hls/epg_0.m3p4`, чтобы обрезать расширение.  Добавить в секцию `server`:

```
rewrite ^/btv/live/(.*)/(.*)\.(.*)$ /btv/live/$1/$2 last;
rewrite ^/btv/catchup/(.*)/(.*)\.(.*)$ /btv/catchup/$1/$2 last;
```

7.5. Поддержка https - было решено не реализовывать в проекте https, а перенаправлять его запросы через NGINX.
Добавить отдельную секцию `server` со всеми предыдущими настройками и:

```
listen 443 ssl;
server_name server.domain.name;

ssl_certificate     /path/to/certificate/file.crt;
ssl_certificate_key /path/to/certificate/file.key;
```

8. После этого - можно деплоить. Файл будет задеплоен а папку `/home/admintv/cti_kaltura`. 
* Запуск `/home/admintv/cti_kaltura/bin/cti_kaltura start`;
* Остановка `/home/admintv/cti_kaltura/bin/cti_kaltura stop`;
* Подключиться к работающему проекту `/home/admintv/cti_kaltura/bin/cti_kaltura remote_console`;
* Запустить проект и подключиться к консоли(при выходе проект завершится) `/home/admintv/cti_kaltura/bin/cti_kaltura console`.


# Кластеризация

Чтобы запустить кластер локально, необходимо в двух разных терминалах выполнить следующие команды:

1. PORT=4000 API_PORT=4001 iex --name first@127.0.0.1 -S mix phx.server
2. PORT=4002 API_PORT=4003 iex --name second@127.0.0.1 -S mix phx.server

После этого в системе появятся два `beam` процесса, с именами `first@127.0.0.1` и `second@127.0.0.1`.
А в каждой запущенных консолей можно запустить `:observer.start()`, чтобы наблюдать за состоянием ядра.

*Важно сделать Mnesia кластерной.* В разделе "Кластеризация mnesia" описанны причины и решение проблемы.

## Реализация кластеризации

Кластеризация реализована с помошью библиотеки `libcluster`. Выполнены следующие шаги:

1. Добавлена зависимость в `mix.exs`$
2. Добавлена настройка проекта для стейдж серверов, продакшна и дев окружения. всех остальных режимов в раздел `:libcluster`;
3. Добавлен `{Cluster.Supervisor, [get_topologies(), [name: CtiKaltura.ClusterSupervisor]]}` в дерево процессов
4. Решена проблема кластеризации Mnesia.
 
## Кластеризация Mnesia  

Проблема в том, что мы используем Mnesia со схемой. После запуска проекта в кластере, необходимо удалить старую схему и создать новую.
Затем заново создать все таблицы и заполнить их данными.

Алгоритм следующий:    
1. Оба узла должны быть одновременно запущены;
2. Необходимо остановить Mnesia на обоих узлах;
3. На одном из них создать схему, в которой указать названия обоих действующих узлов;
4. Затем запустить Mnesia на обоих узлах;
5. Заново создать все таблицы DomainModel и добавить индексы;
6. Затем необходимо запустить `CtiKaltura.Services.DomainModelCache.get_all_records()`.

Аналогичный алгоритм работы для единственного кластера за исключением того, что запуск и остановка происходят на одном ядре.

Для решения этих проблем были написанны два скрипта:

1. CtiKaltura.Workers.ReleaseTasksWorker.make_mnesia_cluster_again() - для кластера (оба ядра должны быть запущены);
2. CtiKaltura.Workers.ReleaseTasksWorker.reset_single_mnesia() - для не кластерной реализации (локально мы работаем в кластере).

Они отрабатывают или выводят сообщение в консоль об ошибке. Их надо запускать из консоли запущенного проекта.

Для стейджа и продакшн режима были написанны команды:

1. `~/cti_kaltura/bin/cti_kaltura make_mnesia_cluster_again` - аналогичный скрипт для запуске на кластере.
После его запуска на каждом из стейджей, в корне проекта обновится папка `Mnesia.<node_name>@<ip_address>`
2. `~/cti_kaltura/bin/cti_kaltura make_single_mnesia_node` - аналогично но для одного ядра.
